{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niwanshu16/FDSP2019/blob/master/Siamese_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UujibxPZElwV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "50e00700-76c4-4ffd-bb9e-17bfc1d59b56"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5NGxtmLExY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "os.chdir('/content/drive/My Drive/DeepLearning/Omniglot')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PNb0vEBFFKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tFAOBApHx5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "from keras.engine.topology import Layer\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import numpy.random as rng"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAsBC8uYFog_",
        "colab_type": "text"
      },
      "source": [
        "Loading the images from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyavwZ29FZF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('train.pickle', 'rb') as f:\n",
        "  (Xtrain,train_classes) = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYVxh8Z7NVT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('test.pickle' , 'rb') as f:\n",
        "  (Xval , val_classes) = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCv66yYEFwKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_weights(shape , name = None):\n",
        "  return np.random.normal(loc =0.0 , scale = 1e-2 , size = shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmD3mm77Fmz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_bias(shape , name = None):\n",
        "    return np.random.normal(loc =0.5 , scale = 1e-2 , size = shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SI-lGVBHGWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_siamese_model(input_shape):\n",
        "    \"\"\"\n",
        "        Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the tensors for the two input images\n",
        "    left_input = Input(input_shape) # First input image\n",
        "    right_input = Input(input_shape) # Secong input image\n",
        "    \n",
        "    # Convolutional Neural Network\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,\n",
        "                   kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(128, (7,7), activation='relu',\n",
        "                     kernel_initializer=initialize_weights,\n",
        "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(128, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
        "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(256, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
        "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='sigmoid',\n",
        "                   kernel_regularizer=l2(1e-3),\n",
        "                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
        "    \n",
        "    # Generate the encodings (feature vectors) for the two images\n",
        "    encoded_l = model(left_input)\n",
        "    encoded_r = model(right_input)\n",
        "    \n",
        "    # Add a customized layer to compute the absolute difference between the encodings\n",
        "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
        "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
        "    \n",
        "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
        "    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(L1_distance)\n",
        "    \n",
        "    # Connect the inputs with the outputs\n",
        "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
        "    return siamese_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty-uwkTBIGoN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "4310e2f2-9b22-4312-8b87-75122086f2ae"
      },
      "source": [
        "model = get_siamese_model((105,105,3))\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0728 05:46:53.119364 140298660845440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0728 05:46:53.164232 140298660845440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0728 05:46:53.209200 140298660845440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0728 05:46:56.326979 140298660845440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 105, 105, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 105, 105, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 4096)         38960448    input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 4096)         0           sequential_1[1][0]               \n",
            "                                                                 sequential_1[2][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            4097        lambda_1[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 38,964,545\n",
            "Trainable params: 38,964,545\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_yixA72ITRG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "019b3c41-e447-4a8d-c6f0-a919f9dac430"
      },
      "source": [
        "optimizer = Adam(lr = 0.00006)\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0728 05:48:14.338812 140298660845440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0728 05:48:14.347571 140298660845440 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0728 05:48:14.355105 140298660845440 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw8hupKtIbOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch(batch_size,s=\"train\"):\n",
        "    \"\"\"Create batch of n pairs, half same class, half different class\"\"\"\n",
        "    if s == 'train':\n",
        "        X = Xtrain\n",
        "        categories = train_classes\n",
        "    else:\n",
        "        X = Xval\n",
        "        categories = val_classes\n",
        "    n_classes, n_examples, w, h , classes = X.shape\n",
        "\n",
        "    # randomly sample several classes to use in the batch\n",
        "    categories = rng.choice(n_classes,size=(batch_size,),replace=False)\n",
        "    \n",
        "    # initialize 2 empty arrays for the input image batch\n",
        "    pairs=[np.zeros((batch_size, h, w,3)) for i in range(2)]\n",
        "    \n",
        "    # initialize vector for the targets\n",
        "    targets=np.zeros((batch_size,))\n",
        "    \n",
        "    # make one half of it '1's, so 2nd half of batch has same class\n",
        "    targets[batch_size//2:] = 1\n",
        "    for i in range(batch_size):\n",
        "        category = categories[i]\n",
        "        idx_1 = rng.randint(0, n_examples)\n",
        "        pairs[0][i,:,:,:] = X[category, idx_1].reshape(w, h, 3)\n",
        "        idx_2 = rng.randint(0, n_examples)\n",
        "        \n",
        "        # pick images of same class for 1st half, different for 2nd\n",
        "        if i >= batch_size // 2:\n",
        "            category_2 = category  \n",
        "        else: \n",
        "            # add a random number to the category modulo n classes to ensure 2nd image has a different category\n",
        "            category_2 = (category + rng.randint(1,n_classes)) % n_classes\n",
        "        \n",
        "        pairs[1][i,:,:,:] = X[category_2,idx_2].reshape(w, h,3)\n",
        "    \n",
        "    return pairs, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoA3tBteJPy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def generate(batch_size, s=\"train\"):\n",
        "    \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
        "    while True:\n",
        "        pairs, targets = get_batch(batch_size,s)\n",
        "        yield (pairs, targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIzTu697JS9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_oneshot_task(N, s=\"val\", language=None):\n",
        "    \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
        "    if s == 'train':\n",
        "        X = Xtrain\n",
        "        categories = train_classes\n",
        "    else:\n",
        "        X = Xval\n",
        "        categories = val_classes\n",
        "    n_classes, n_examples, w, h , channels = X.shape\n",
        "    \n",
        "    indices = rng.randint(0, n_examples,size=(N,))\n",
        "    if language is not None: # if language is specified, select characters for that language\n",
        "        low, high = categories[language]\n",
        "        if N > high - low:\n",
        "            raise ValueError(\"This language ({}) has less than {} letters\".format(language, N))\n",
        "        categories = rng.choice(range(low,high),size=(N,),replace=False)\n",
        "\n",
        "    else: # if no language specified just pick a bunch of random letters\n",
        "        categories = rng.choice(range(n_classes),size=(N,),replace=False)            \n",
        "    true_category = categories[0]\n",
        "    ex1, ex2 = rng.choice(n_examples,replace=False,size=(2,))\n",
        "    test_image = np.asarray([X[true_category,ex1,:,:]]*N).reshape(N, w, h,3)\n",
        "    support_set = X[categories,indices,:,:]\n",
        "    support_set[0,:,:] = X[true_category,ex2]\n",
        "    support_set = support_set.reshape(N, w, h,3)\n",
        "    targets = np.zeros((N,))\n",
        "    targets[0] = 1\n",
        "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
        "    pairs = [test_image,support_set]\n",
        "\n",
        "    return pairs, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd-8g7KtJf6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_oneshot(model, N, k, s = \"val\", verbose = 0):\n",
        "    \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
        "    n_correct = 0\n",
        "    if verbose:\n",
        "        print(\"Evaluating model on {} random {} way one-shot learning tasks ... \\n\".format(k,N))\n",
        "    for i in range(k):\n",
        "        inputs, targets = make_oneshot_task(N,s)\n",
        "        probs = model.predict(inputs)\n",
        "        if np.argmax(probs) == np.argmax(targets):\n",
        "            n_correct+=1\n",
        "    percent_correct = (100.0 * n_correct / k)\n",
        "    if verbose:\n",
        "        print(\"Got an average of {}% {} way one-shot learning accuracy \\n\".format(percent_correct,N))\n",
        "    return percent_correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVA5u101Jllp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyper parameters\n",
        "evaluate_every = 200 # interval for evaluating on one-shot tasks\n",
        "batch_size = 32\n",
        "n_iter = 20000 # No. of training iterations\n",
        "N_way = 20 # how many classes for testing one-shot tasks\n",
        "n_val = 250 # how many one-shot tasks to validate on\n",
        "best = -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB41sX_qJsbM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2fc36e19-27cb-4c95-881c-1d4da9e2537d"
      },
      "source": [
        "model_path = os.getcwd()\n",
        "print(\"Starting training process!\")\n",
        "print(\"-------------------------------------\")\n",
        "t_start = time.time()\n",
        "for i in range(1, n_iter+1):\n",
        "    (inputs,targets) = get_batch(batch_size)\n",
        "    loss = model.train_on_batch(inputs, targets)\n",
        "    if i % evaluate_every == 0:\n",
        "        print(\"\\n ------------- \\n\")\n",
        "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
        "        print(\"Train Loss: {0}\".format(loss)) \n",
        "        val_acc = test_oneshot(model, N_way, n_val, verbose=True)\n",
        "        if val_acc >= best:\n",
        "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
        "            best = val_acc"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training process!\n",
            "-------------------------------------\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 200 iterations: 0.35145366191864014 mins\n",
            "Train Loss: 1.0944441556930542\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 57.6% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 57.6, previous best: -1\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 400 iterations: 0.7704501350720724 mins\n",
            "Train Loss: 1.0198482275009155\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 56.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 600 iterations: 1.1926089564959208 mins\n",
            "Train Loss: 0.9260221123695374\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 60.0% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 60.0, previous best: 57.6\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 800 iterations: 1.6181363344192505 mins\n",
            "Train Loss: 0.8151314854621887\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 66.8% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 66.8, previous best: 60.0\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1000 iterations: 2.0456566413243613 mins\n",
            "Train Loss: 0.6333094239234924\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 63.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1200 iterations: 2.472711698214213 mins\n",
            "Train Loss: 0.7004063725471497\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 68.4% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 68.4, previous best: 66.8\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1400 iterations: 2.899441448847453 mins\n",
            "Train Loss: 0.6283024549484253\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 64.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1600 iterations: 3.3266520619392397 mins\n",
            "Train Loss: 0.6068906784057617\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 71.2% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 71.2, previous best: 68.4\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 1800 iterations: 3.7541826248168944 mins\n",
            "Train Loss: 0.621478259563446\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 64.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2000 iterations: 4.18160427014033 mins\n",
            "Train Loss: 0.5565012097358704\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 72.8% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 72.8, previous best: 71.2\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2200 iterations: 4.608467757701874 mins\n",
            "Train Loss: 0.5075029134750366\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2400 iterations: 5.034579030672709 mins\n",
            "Train Loss: 0.47314149141311646\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 61.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2600 iterations: 5.460876552263896 mins\n",
            "Train Loss: 0.4177856743335724\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 2800 iterations: 5.88654104868571 mins\n",
            "Train Loss: 0.42856690287590027\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 67.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3000 iterations: 6.314384953180949 mins\n",
            "Train Loss: 0.47651660442352295\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 69.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3200 iterations: 6.740360764662425 mins\n",
            "Train Loss: 0.45138972997665405\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 64.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3400 iterations: 7.16673534711202 mins\n",
            "Train Loss: 0.45146092772483826\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 70.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3600 iterations: 7.59646567106247 mins\n",
            "Train Loss: 0.4373418986797333\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 72.8% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 72.8, previous best: 72.8\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 3800 iterations: 8.023018491268157 mins\n",
            "Train Loss: 0.5753387212753296\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.4% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 76.4, previous best: 72.8\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4000 iterations: 8.453394949436188 mins\n",
            "Train Loss: 0.3962165415287018\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4200 iterations: 8.881630770365398 mins\n",
            "Train Loss: 0.3240770697593689\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4400 iterations: 9.312021160125733 mins\n",
            "Train Loss: 0.2925863564014435\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4600 iterations: 9.742033958435059 mins\n",
            "Train Loss: 0.3559595048427582\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 4800 iterations: 10.168468638261158 mins\n",
            "Train Loss: 0.27879542112350464\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5000 iterations: 10.597784717877706 mins\n",
            "Train Loss: 0.38874661922454834\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5200 iterations: 11.02456826766332 mins\n",
            "Train Loss: 0.30151546001434326\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5400 iterations: 11.451358143488566 mins\n",
            "Train Loss: 0.28034645318984985\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.2% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 77.2, previous best: 76.4\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5600 iterations: 11.881440460681915 mins\n",
            "Train Loss: 0.32591748237609863\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.8% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 78.8, previous best: 77.2\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 5800 iterations: 12.309068771203359 mins\n",
            "Train Loss: 0.2292182892560959\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6000 iterations: 12.736549011866252 mins\n",
            "Train Loss: 0.24552516639232635\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6200 iterations: 13.164205145835876 mins\n",
            "Train Loss: 0.44748005270957947\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6400 iterations: 13.591664604345958 mins\n",
            "Train Loss: 0.23010164499282837\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6600 iterations: 14.019041514396667 mins\n",
            "Train Loss: 0.28404268622398376\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 6800 iterations: 14.446719952424367 mins\n",
            "Train Loss: 0.2633759379386902\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7000 iterations: 14.874485075473785 mins\n",
            "Train Loss: 0.22676222026348114\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 77.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7200 iterations: 15.301246647040049 mins\n",
            "Train Loss: 0.3062402904033661\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7400 iterations: 15.728513451417287 mins\n",
            "Train Loss: 0.27440258860588074\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7600 iterations: 16.155976641178132 mins\n",
            "Train Loss: 0.2993895411491394\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.2% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 79.2, previous best: 78.8\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 7800 iterations: 16.58337466319402 mins\n",
            "Train Loss: 0.24986113607883453\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8000 iterations: 17.010066266854604 mins\n",
            "Train Loss: 0.2605421543121338\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 80.0, previous best: 79.2\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8200 iterations: 17.436731747786204 mins\n",
            "Train Loss: 0.2875802218914032\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8400 iterations: 17.863267425696055 mins\n",
            "Train Loss: 0.19802358746528625\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 83.6% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 83.6, previous best: 80.0\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8600 iterations: 18.28987840016683 mins\n",
            "Train Loss: 0.2242974191904068\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 8800 iterations: 18.716315146287283 mins\n",
            "Train Loss: 0.23537229001522064\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9000 iterations: 19.14330124060313 mins\n",
            "Train Loss: 0.21378231048583984\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9200 iterations: 19.570631766319273 mins\n",
            "Train Loss: 0.3718060851097107\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9400 iterations: 19.997579236825306 mins\n",
            "Train Loss: 0.19671551883220673\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9600 iterations: 20.424630999565125 mins\n",
            "Train Loss: 0.31369879841804504\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 9800 iterations: 20.851310757795968 mins\n",
            "Train Loss: 0.22405694425106049\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10000 iterations: 21.277849940458932 mins\n",
            "Train Loss: 0.2324279546737671\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10200 iterations: 21.70419955253601 mins\n",
            "Train Loss: 0.29785001277923584\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10400 iterations: 22.1303684314092 mins\n",
            "Train Loss: 0.3405211865901947\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10600 iterations: 22.556954566637675 mins\n",
            "Train Loss: 0.2965565621852875\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 10800 iterations: 22.983173966407776 mins\n",
            "Train Loss: 0.31008684635162354\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 73.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11000 iterations: 23.409740134080252 mins\n",
            "Train Loss: 0.3966865539550781\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11200 iterations: 23.83590817451477 mins\n",
            "Train Loss: 0.2833765745162964\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 72.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11400 iterations: 24.262492767969768 mins\n",
            "Train Loss: 0.3550844192504883\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.8% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 86.8, previous best: 83.6\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11600 iterations: 24.689469933509827 mins\n",
            "Train Loss: 0.25692257285118103\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 11800 iterations: 25.11653762261073 mins\n",
            "Train Loss: 0.185562863945961\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12000 iterations: 25.54353382984797 mins\n",
            "Train Loss: 0.21508511900901794\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12200 iterations: 25.97048257191976 mins\n",
            "Train Loss: 0.36742618680000305\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12400 iterations: 26.39763001203537 mins\n",
            "Train Loss: 0.16593265533447266\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12600 iterations: 26.824384693304697 mins\n",
            "Train Loss: 0.21064969897270203\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 12800 iterations: 27.251205241680147 mins\n",
            "Train Loss: 0.15342967212200165\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13000 iterations: 27.67784620920817 mins\n",
            "Train Loss: 0.3764342963695526\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13200 iterations: 28.10486943721771 mins\n",
            "Train Loss: 0.1843322515487671\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13400 iterations: 28.531766041119894 mins\n",
            "Train Loss: 0.19631068408489227\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13600 iterations: 28.958497405052185 mins\n",
            "Train Loss: 0.30965930223464966\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 13800 iterations: 29.385466555754345 mins\n",
            "Train Loss: 0.16699203848838806\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14000 iterations: 29.813025200366972 mins\n",
            "Train Loss: 0.34186458587646484\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14200 iterations: 30.240331637859345 mins\n",
            "Train Loss: 0.1777145266532898\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14400 iterations: 30.667153104146323 mins\n",
            "Train Loss: 0.32941097021102905\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14600 iterations: 31.094024848937988 mins\n",
            "Train Loss: 0.18397724628448486\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 14800 iterations: 31.52037105957667 mins\n",
            "Train Loss: 0.1746804565191269\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15000 iterations: 31.9466845591863 mins\n",
            "Train Loss: 0.254038006067276\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15200 iterations: 32.3736014842987 mins\n",
            "Train Loss: 0.20016399025917053\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15400 iterations: 32.80079119602839 mins\n",
            "Train Loss: 0.1609218418598175\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15600 iterations: 33.227336589495344 mins\n",
            "Train Loss: 0.20025132596492767\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 15800 iterations: 33.650352760156 mins\n",
            "Train Loss: 0.16181983053684235\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16000 iterations: 34.07557062705358 mins\n",
            "Train Loss: 0.2335132658481598\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 76.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16200 iterations: 34.4977556904157 mins\n",
            "Train Loss: 0.18522882461547852\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 85.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16400 iterations: 34.9195718050003 mins\n",
            "Train Loss: 0.14155741035938263\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16600 iterations: 35.342498151461285 mins\n",
            "Train Loss: 0.27017733454704285\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 16800 iterations: 35.764283601442976 mins\n",
            "Train Loss: 0.29619815945625305\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17000 iterations: 36.18691298564275 mins\n",
            "Train Loss: 0.21830256283283234\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 74.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17200 iterations: 36.609411080678306 mins\n",
            "Train Loss: 0.16256731748580933\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17400 iterations: 37.03176257610321 mins\n",
            "Train Loss: 0.17138901352882385\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17600 iterations: 37.454238057136536 mins\n",
            "Train Loss: 0.17196854948997498\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 17800 iterations: 37.87707504431407 mins\n",
            "Train Loss: 0.2018677443265915\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.8% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18000 iterations: 38.2997037212054 mins\n",
            "Train Loss: 0.1499311774969101\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18200 iterations: 38.72182669639587 mins\n",
            "Train Loss: 0.22369977831840515\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 81.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18400 iterations: 39.14434038003286 mins\n",
            "Train Loss: 0.17499330639839172\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.8% 20 way one-shot learning accuracy \n",
            "\n",
            "Current best: 86.8, previous best: 86.8\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18600 iterations: 39.56652178366979 mins\n",
            "Train Loss: 0.1892494410276413\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 18800 iterations: 39.98879358371099 mins\n",
            "Train Loss: 0.3917381763458252\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 79.2% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19000 iterations: 40.41240795056025 mins\n",
            "Train Loss: 0.17635303735733032\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19200 iterations: 40.83450267314911 mins\n",
            "Train Loss: 0.18480369448661804\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 86.4% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19400 iterations: 41.25616029103597 mins\n",
            "Train Loss: 0.21862083673477173\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 82.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19600 iterations: 41.678194812933604 mins\n",
            "Train Loss: 0.22166302800178528\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 19800 iterations: 42.1003053466479 mins\n",
            "Train Loss: 0.14996536076068878\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 75.6% 20 way one-shot learning accuracy \n",
            "\n",
            "\n",
            " ------------- \n",
            "\n",
            "Time for 20000 iterations: 42.522380805015565 mins\n",
            "Train Loss: 0.16666527092456818\n",
            "Evaluating model on 250 random 20 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 80.0% 20 way one-shot learning accuracy \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rUGsdFTJ3Qs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'weights_20000.hdf5'\n",
        "model.save_weights(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqnsk_ggY5Av",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nearest_neighbour(pairs,targets):\n",
        "  L2_distances = np.zeros_like(targets)\n",
        "  for i in range(len(targets)):\n",
        "    L2_distances[i] = np.sum(np.sqrt(pairs[0][i]**2 - pairs[1][i]**2))\n",
        "  if np.argmin(L2_distances)==np.argmax(targets):\n",
        "    return 1\n",
        "  return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi7zvWYjad8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nn_accuracy(N_ways , n_trials):\n",
        "  print(\"Evaluating nearest neighbour on {} unique {} way one-shot learning tasks ...\".format(n_trials,N_ways))\n",
        "  n_right = 0\n",
        "  for i in range(n_trials):\n",
        "    pairs , targets = make_oneshot_task(N_ways , \"val\")\n",
        "    correct = nearest_neighbour(pairs , targets)\n",
        "    n_right += correct\n",
        "  return 100.0 *n_right / n_trials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsB7o50dbrjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ways = np.arange(1,20,2)\n",
        "resume =  False\n",
        "trials = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNQSB69Abswf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c38dba0f-da08-4817-bb1d-468d6ffa7501"
      },
      "source": [
        "val_accs, train_accs,nn_accs = [], [], []\n",
        "for N in ways:    \n",
        "    val_accs.append(test_oneshot(model, N, trials, \"val\", verbose=True))\n",
        "    train_accs.append(test_oneshot(model, N, trials, \"train\", verbose=True))\n",
        "    nn_acc = nn_accuracy(N, trials)\n",
        "    nn_accs.append(nn_acc)\n",
        "    print (\"NN Accuracy = \", nn_acc)\n",
        "    print(\"---------------------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating model on 50 random 1 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 100.0% 1 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 1 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 100.0% 1 way one-shot learning accuracy \n",
            "\n",
            "Evaluating nearest neighbour on 50 unique 1 way one-shot learning tasks ...\n",
            "NN Accuracy =  100.0\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Evaluating model on 50 random 3 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 100.0% 3 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 3 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 100.0% 3 way one-shot learning accuracy \n",
            "\n",
            "Evaluating nearest neighbour on 50 unique 3 way one-shot learning tasks ...\n",
            "NN Accuracy =  64.0\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Evaluating model on 50 random 5 way one-shot learning tasks ... \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Got an average of 94.0% 5 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 5 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 98.0% 5 way one-shot learning accuracy \n",
            "\n",
            "Evaluating nearest neighbour on 50 unique 5 way one-shot learning tasks ...\n",
            "NN Accuracy =  44.0\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Evaluating model on 50 random 7 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 92.0% 7 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 7 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 98.0% 7 way one-shot learning accuracy \n",
            "\n",
            "Evaluating nearest neighbour on 50 unique 7 way one-shot learning tasks ...\n",
            "NN Accuracy =  50.0\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Evaluating model on 50 random 9 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 84.0% 9 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 9 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 96.0% 9 way one-shot learning accuracy \n",
            "\n",
            "Evaluating nearest neighbour on 50 unique 9 way one-shot learning tasks ...\n",
            "NN Accuracy =  42.0\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Evaluating model on 50 random 11 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 90.0% 11 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 11 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 100.0% 11 way one-shot learning accuracy \n",
            "\n",
            "Evaluating nearest neighbour on 50 unique 11 way one-shot learning tasks ...\n",
            "NN Accuracy =  36.0\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Evaluating model on 50 random 13 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 94.0% 13 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 13 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 96.0% 13 way one-shot learning accuracy \n",
            "\n",
            "Evaluating nearest neighbour on 50 unique 13 way one-shot learning tasks ...\n",
            "NN Accuracy =  22.0\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Evaluating model on 50 random 15 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 92.0% 15 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 15 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 98.0% 15 way one-shot learning accuracy \n",
            "\n",
            "Evaluating nearest neighbour on 50 unique 15 way one-shot learning tasks ...\n",
            "NN Accuracy =  30.0\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Evaluating model on 50 random 17 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 17 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 17 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 100.0% 17 way one-shot learning accuracy \n",
            "\n",
            "Evaluating nearest neighbour on 50 unique 17 way one-shot learning tasks ...\n",
            "NN Accuracy =  26.0\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "Evaluating model on 50 random 19 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 78.0% 19 way one-shot learning accuracy \n",
            "\n",
            "Evaluating model on 50 random 19 way one-shot learning tasks ... \n",
            "\n",
            "Got an average of 98.0% 19 way one-shot learning accuracy \n",
            "\n",
            "Evaluating nearest neighbour on 50 unique 19 way one-shot learning tasks ...\n",
            "NN Accuracy =  22.0\n",
            "---------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d0tHNVsb81o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def concat_images(X):\n",
        "    \"\"\"Concatenates a bunch of images into a big matrix for plotting purposes.\"\"\"\n",
        "    nc, h , w, _ , _ = X.shape\n",
        "    X = X.reshape(nc, h, w , 3)\n",
        "    n = np.ceil(np.sqrt(nc)).astype(\"int8\")\n",
        "    img = np.zeros((n*w,n*h))\n",
        "    x = 0\n",
        "    y = 0\n",
        "    for example in range(nc):\n",
        "        img[x*w:(x+1)*w,y*h:(y+1)*h] = X[example]\n",
        "        y += 1\n",
        "        if y >= n:\n",
        "            y = 0\n",
        "            x += 1\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3PoGO3dchE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input two images\n",
        "img1 = cv2.imread('img1.jpeg')\n",
        "img2 = cv2.imread('img2.jpeg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rrl7RyBeAyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua8EJaY-eCHK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0f8ebc38-db83-47ed-e741-b0856c50e776"
      },
      "source": [
        "img2.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105, 105, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tZDBTHyeFCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img1 = cv2.resize(img1 , (105,105))\n",
        "img2 = cv2.resize(img2 , (105,105))\n",
        "img1 = np.array(img1)\n",
        "img2 = np.array(img2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYbjolx5kyVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img1 = np.reshape(img1 ,(1,105,105,3))\n",
        "img2 = np.reshape(img2 ,(1,105,105,3))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH6BL4w3eNUl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5b9dcde2-1bba-43ce-eeff-12e4bccf5233"
      },
      "source": [
        "pairs_test = [[img1,img1]]\n",
        "pairs_test[0][1].shape\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 105, 105, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ftE1m20fGvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "ce3c2436-f646-42c6-ce7f-c7671c7f09ee"
      },
      "source": [
        "plt.imshow(pairs_test[0][0])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f992447f198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9UOhttpqm7L/D/7TWXa/OAoZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfgmZ8fofIo5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1d6e9e3e-b5f6-47d1-9b9e-0f7be6b0fd53"
      },
      "source": [
        "model.predict(pairs_test[0])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7410376]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ia7IPf2gZrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}